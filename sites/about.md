# üßëüèº‚Äçüíª √úber ParteiPapagei
_Demokratie ist der Wettbewerb politischer Ideen. Die Parteien stellen ihre Ideen in ihrem Programm vor und am Wahltag entscheiden die W√§hler, welche Idee sie am √ºberzeugendensten finden. Mit ParteiPapagei wollen wir diese Ideen dem W√§hler leichter zug√§nglich machen._


ParteiPapagei wurde von Tim Baumg√§rtner entwickelt und ist ein Open-Source-Projekt. Der Quellcode ist auf [GitHub](https://github.com/timbmg/ParteiPapagei) verf√ºgbar. Es wird keine Garantie f√ºr die Richtigkeit der generierten Inhalte √ºbernommen. Die Informationen sind nicht verbindlich und dienen nur zur Bildung und Unterhaltung. Die Verwendung der Informationen erfolgt auf eigene Gefahr. Siehe auch den [Disclaimer](/disclaimer) und die [Datenschutzbestimmungen](/data-protection).

F√ºr Fragen und Anregungen k√∂nnen Sie mich unter [baumgaertner.t@gmail.com](mailto:baumgaertner.t@gmail.com) erreichen.

F√ºr Feature Requests und Bug Reports k√∂nnen Sie gerne ein [Issue](https://github.com/timbmg/ParteiPapagei/issues) auf GitHub erstellen.

ü§≤ Falls Du ParteiPapagei hilfreich findest und einen Teil zu den laufenden Kosten beitragen kannst, unterst√ºze mich gerne auf [Ko-fi](https://ko-fi.com/timbmg).

## Technologie
ParteiPapagei basiert auf Retrieval Augmented Generation (RAG) [[1](#refRAG)]. Dabei wird eine Suche mit einem Large Language Model (LLM) verkn√ºpft. Im Fall von ParteiPapagei werden zun√§chst relevante Passagen aus dem Wahlprogramm gesucht, basierend auf der Eingabe des Nutzers. Abschlie√üend werden die relevanten Passagen genutzt, um eine Antwort zu generieren.

![RAG](./rag.png)

### Preprocessing
Zun√§chst wurden die PDFs der Wahlprogramme halb-automatisch in Markdown √ºberf√ºhrt. Anschlie√üend wird der Text in Passagen unterteilt, falls diese noch zu lang sind, werden sie wiederum aufgeteilt ("Chunking"). Zus√§tzlich zum Text wird au√üerdem die √úberschrift der Passagen gespeichert, um den Kontext der Passage sp√§ter besser zu verstehen.

### Textanalyse
Die Passagen des Preprocessings werden anschlie√üend einer Schlagwort- und Semantischen Analyse unterzogen. Dabei werden die Schlagw√∂rter der Passagen extrahiert und gespeichert. Zus√§tzlich wird eine semantische Repr√§sentation der Passagen erstellt, um Passagen nicht nur anhand von Schlagw√∂rtern, sondern auch anhand des Inhalts zu finden.

### Fragen Verarbeitung
Basierend auf der Frage des Nutzers werden zun√§chst √§hnliche Fragen generiert. Dies dient dazu, mehr relevante Schlagw√∂rter oder andere Informationen aus dem Wahlprogramm zu finden, die so nicht direkt in der Frage enthalten sind. Anschlie√üend werden die Fragen derselben Textanalyse unterzogen wie die Passagen.

### Suche
Als Suche nutzt ParteiPapagei dabei zum einen eine Schlagwortsuche (BM25 [[2](#refBM25)]), zum anderen eine semantische Suche basierend auf einem Dense Retriever. Die semantische Suche wird durch Googles Gemini Model (`models/text-embedding-004`) [[3](#refGecko)] realisiert. 
Nachdem sowohl die Wahlprogramme, als auch die Suchanfrage in eine semantische Repr√§sentation umgewandelt wurden, wird die √Ñhnlichkeit zwischen den beiden Repr√§sentationen berechnet. Am Ende werden die Passagen aus den Wahlprogrammen zur√ºckgegeben, die die h√∂chste √Ñhnlichkeit zur Suchanfrage aufweisen. Die Ergebnisse der beiden Repr√§sentationen werden dabei fusioniert [[4](#refRR)].


### Antwortgenerierung
Die Passagen aus dem Wahlprogramm, die durch die Suche gefunden wurden, werden dann genutzt, um eine Antwort zu generieren. Dabei wird ein Large Language Model (LLM) genutzt. In ParteiPapagei wird Google's Gemini Model (`models/gemini-1.5-flash-002`) [[5](#refGemini)] verwendet. Dabei handelt es sich um ein relativ kleines Modell, das zwar nicht so leistungsstark wie gr√∂√üere Modelle ist, aber relativ g√ºnstig genutzt werden kann. Au√üer der Generierung der Antwort wird das Modell instruiert, die Passagen aus dem Wahlprogramm zu zitieren. Diese werden dann als Links in der Antwort angezeigt, sodass der Nutzer die Quelle √ºberpr√ºfen kann.

### Einschr√§nkungen
- ParteiPapagei besitzt kein "Ged√§chtnis" und ber√ºcksichtigt Kontext (also die vorherigen Nachrichten) zur Beantwortung der Fragen nicht. D.h. jede Frage wird unabh√§ngig beantwortet und Folgefragen k√∂nnen nicht auf vorherige Antworten Bezug nehmen.
- ParteiPapagei kann nur auf die Informationen in den Wahlprogrammen zugreifen. Es kann keine aktuellen Informationen oder Meinungen zu politischen Themen geben.
- Erfahrungsgem√§√ü funktionieren sehr allgemein gehaltene Fragen weniger gut, da die Suche nach relevanten Passagen schwieriger ist.
- ParteiPapagei benutzt LLMs f√ºr die Suche und Generierung von Antworten. Diese Modelle sind nicht immer neutral und k√∂nnen bestimmte Bias enthalten [[6](refBias)].

## Referenzen

<a name="refRAG"></a>[1] Lewis, Patrick, et al. ["Retrieval-augmented generation for knowledge-intensive nlp tasks."](https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf) Advances in Neural Information Processing Systems 33 (2020): 9459-9474.

<a name="refBM25"></a>[2] Robertson, Stephen, and Hugo Zaragoza. ["The probabilistic relevance framework: BM25 and beyond."](https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf) Foundations and Trends¬Æ in Information Retrieval 3.4 (2009): 333-389.

<a name="refGecko"></a>[3] Lee, Jinhyuk, et al. ["Gecko: Versatile text embeddings distilled from large language models."](https://arxiv.org/pdf/2403.20327) arXiv preprint arXiv:2403.20327 (2024).

<a name="refRR"></a>[4] Cormack, Gordon V., Charles LA Clarke, and Stefan Buettcher. ["Reciprocal rank fusion outperforms condorcet and individual rank learning methods."](https://dl.acm.org/doi/pdf/10.1145/1571941.1572114) Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval. 2009.

<a name="refGemini"></a>[5] Team, Gemini, et al. ["Gemini: a family of highly capable multimodal models."](https://arxiv.org/pdf/2312.11805) arXiv preprint arXiv:2312.11805 (2023).

<a name="refBias"></a>[6] Yejin Bang, Delong Chen, Nayeon Lee, Pascale Fung. ["Measuring Political Bias in Large Language Models: What Is Said and How It Is Said"](https://aclanthology.org/2024.acl-long.600/) Annual Meeting of the Association for Computational Linguistics. 2024.
